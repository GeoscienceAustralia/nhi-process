{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHIRS usage statistics\n",
    "\n",
    "This notebook provides a first-pass analysis of NHIRS geoserver request logs, to enable NHI to analyse who is using the service, how they are connecting, and trends in use. \n",
    "\n",
    "The log file is comprised of a timestamp and a JSON message that contains information on the request, which needs to be parsed to separate out the useful information.\n",
    "\n",
    "### Notes:\n",
    "\n",
    "* Presently there's only one dump of the log files from early September 2024. There's a [JIRA ticket with the Flying Hellfish](https://gajira.atlassian.net/browse/NHIRS-218) to create a process to save the logs on a regular basis.\n",
    "\n",
    "\n",
    "### Requirements\n",
    "\n",
    "* pandas\n",
    "* geopandas\n",
    "* cartopy\n",
    "* seaborn\n",
    "\n",
    "\n",
    "### Last updated:\n",
    "\n",
    "Craig Arthur\n",
    "September 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from urllib.request import urlopen\n",
    "import urllib.parse\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "PROJECTION = ccrs.PlateCarree(central_longitude=180)\n",
    "TRANSFORM = ccrs.PlateCarree()\n",
    "\n",
    "#states = cfeature.NaturalEarthFeature(\n",
    "#    category='cultural',\n",
    "#    name='admin_1_states_provinces_lines',\n",
    "#    scale='10m',\n",
    "#    facecolor='none')\n",
    "#LAND = cfeature.LAND()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r\"C:\\Users\\u12161\\Downloads\\NHIRS geoserver request logs.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We restrict to a subset of the URIs, so we focus on those that are requesting the geoserver endpoints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "uris = ['/geoserver/nhirs/ows', '/geoserver/nhirs/wfs', '/geoserver/nhirs/wms',\n",
    "        '/geoserver/access/ows', '/geoserver/access/wfs', '/geoserver/access/wms']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a collection of functions to manipulate the messages. Some of these extract information from the JSON message, others clean strings to remove HTML ascii codes that appear in some parts of the messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(string):\n",
    "    cleaned = string.replace('%27', '')\n",
    "    cleaned = re.sub(r\"^'|'$\", '', cleaned)\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_message(message):\n",
    "    # Initialize an empty dictionary\n",
    "    parsed_dict = {}\n",
    "    \n",
    "    # Split the message by '&' to get key-value pairs\n",
    "    pairs = message.split('&')\n",
    "    \n",
    "    # Loop through each pair and split by '=' to get key and value\n",
    "    for pair in pairs:\n",
    "        if '=' in pair:\n",
    "            key, value = pair.split('=', 1)  # Split by the first '='\n",
    "            # Decode the value in case it's URL encoded\n",
    "            decoded_value = urllib.parse.unquote(value)\n",
    "            parsed_dict[key] = decoded_value\n",
    "        else:\n",
    "            parsed_dict[pair] = None  # Handle cases where there's no '=' (if needed)\n",
    "    \n",
    "    return parsed_dict\n",
    "\n",
    "def extractLayer(msg):\n",
    "    try:\n",
    "        return parse_message(msg)[\"LAYERS\"]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def extractService(msg):\n",
    "    try:\n",
    "        return parse_message(msg)[\"SERVICE\"]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def extractEvent(msg):\n",
    "    try:\n",
    "        cqlquery = parse_message(msg)[\"CQL_FILTER\"]\n",
    "    except:\n",
    "        return None\n",
    "    else:\n",
    "        try:\n",
    "            eventid = parse_message(cqlquery)['event_id']\n",
    "            return clean_string(eventid)\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename)\n",
    "df['datetime'] = pd.to_datetime(df['date'] + ' ' + df['time'])\n",
    "df['event_id'] = df['query_string'].apply(extractEvent)\n",
    "df['layer'] = df['query_string'].apply(extractLayer)\n",
    "df['hour'] = df['datetime'].dt.floor(\"h\")\n",
    "df['day'] = df['datetime'].dt.floor('d')\n",
    "# Select the web service URIs:\n",
    "df = df.loc[df['uri'].isin(uris)]\n",
    "\n",
    "# Filter out my own IP (in fact this should be all GA addresses):\n",
    "df = df.loc[~df['request_ip'].str.startswith('124.47')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of hits from each unique IP address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['request_ip'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of requests from different applications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_agent'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a chart of the hourly rate of requests across all endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "sns.lineplot(df.set_index('datetime').resample('h').size(), ax=ax, ) #marker='o', markersize=5)\n",
    "ax.set_ylabel(\"# requests per hour\")\n",
    "ax.set_xlabel(\"Time (UTC)\")\n",
    "dateloc = mdates.DayLocator(interval=5)\n",
    "datefmt = mdates.DateFormatter('%Y-%m-%d')\n",
    "ax.xaxis.set_major_locator(dateloc)\n",
    "ax.grid()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a stacked bar chart of the daily requests, with separate categories for each URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgroup = df.groupby(['day', 'uri']).size().reset_index(name='request_count')\n",
    "df_pivot = dfgroup.pivot(index='day', columns='uri', values='request_count').fillna(0)\n",
    "df_pivot.index = df_pivot.index.date\n",
    "\n",
    "fig, ax = plt.subplots(1, 1,figsize=(12, 6))\n",
    "ax = df_pivot.plot(kind='bar', stacked=True, ax=ax, rot=90)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Number of Requests')\n",
    "ax.set_title('Number of Requests per day by URI')\n",
    "dateloc = mdates.DayLocator(interval=2)\n",
    "datefmt = mdates.DateFormatter('%Y-%m-%d')\n",
    "ax.xaxis.set_major_locator(dateloc)\n",
    "plt.legend(title='URI', ncols=2)\n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['user_agent', 'request_ip']).size().reset_index(name='application count').to_csv(r\"X:\\georisk\\HaRIA_B_Wind\\projects\\NHIRS\\2. DATA\\1. Work Unit Assessment\\Usage\\20241016_Agent_IP.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a chart of the daily number of unique IP adresses requesting services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of unique IP addresses by day:\n",
    "dfgroup = df.groupby(['day'])['request_ip'].nunique().reset_index(name='IP count').set_index('day')\n",
    "dfgroup.index = dfgroup.index.date\n",
    "\n",
    "fig, ax = plt.subplots(1, 1,figsize=(12, 6))\n",
    "ax = dfgroup.plot(kind='bar', stacked=False, ax=ax, rot=0)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('IP count')\n",
    "ax.set_title('Number of unique IPs')\n",
    "dateloc = mdates.DayLocator(interval=5)\n",
    "datefmt = mdates.DateFormatter('%Y-%m-%d')\n",
    "ax.xaxis.set_major_locator(dateloc)\n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractLocation(ip):\n",
    "    try:\n",
    "        res = urlopen('https://ipinfo.io/' + ip + '/json')\n",
    "        data = json.load(res)\n",
    "        city = data['city']\n",
    "        lon = float(data['loc'].split(',')[0])\n",
    "        lat = float(data['loc'].split(',')[1])\n",
    "        return (city, lon, lat)\n",
    "    except json.JSONDecodeError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we discover the location of the list of IP addresses so we can plot a map of where the services are being used. \n",
    "\n",
    "_Take care with this, as it may raise an access denied error if you provide too long a list_. This makes a request to an IP information page, and if we poll too many times in too short a period, the requests will be blocked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdf = df['request_ip'].value_counts().reset_index()['request_ip'].apply(extractLocation, )\n",
    "locdf = pd.DataFrame(tmpdf.tolist(), index=tmpdf.index, columns=['city', 'latitude', 'longitude'])\n",
    "locdf['request_ip'] = df['request_ip'].value_counts().index\n",
    "locgdf = gpd.GeoDataFrame(data=locdf, geometry=gpd.points_from_xy(locdf['longitude'], locdf['latitude']), crs=TRANSFORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['request_ip'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a map of the IP locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8),\n",
    "                       subplot_kw={'projection': PROJECTION})\n",
    "\n",
    "locgdf.plot(marker=\"*\", color='red', markersize=40, ax=ax, transform=TRANSFORM)\n",
    "ax.coastlines()\n",
    "#ax.add_feature(states, edgecolor='0.15', linestyle='--')\n",
    "#ax.add_feature(cfeature.LAND, edgecolor='k')\n",
    "gl = ax.gridlines(draw_labels=True)\n",
    "ax.set_extent((110, 160, -45, -10), crs=TRANSFORM) # Change this if you want to plot global map\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot table of the applications ('agent') that are used by each unique IP. Typically, there's only one application, but some IP addresses report more than one application, suggesting multiple users are making requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(index='request_ip', columns='user_agent', values='day', aggfunc='count').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.event_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdf = df.loc[df['event_id'].notnull()]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "sns.lineplot(tmpdf.set_index('datetime').resample('h').size(), ax=ax, ) #marker='o', markersize=5)\n",
    "ax.set_ylabel(\"# requests per hour\")\n",
    "ax.set_xlabel(\"Time (UTC)\")\n",
    "dateloc = mdates.DayLocator(interval=5)\n",
    "datefmt = mdates.DateFormatter('%Y-%m-%d')\n",
    "ax.xaxis.set_major_locator(dateloc)\n",
    "ax.grid()\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "process",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
